{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Agent Responses"
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results from our [TrustworthyAgentLite](https://github.com/cleanlab/TrustworthyAgentLite) fork."
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_df = pd.read_csv(\"data/trustworthy_zs_gpt-4.1-mini.csv\")\n",
    "zst_df = pd.read_csv(\"data/trustworthy_zst_gpt-4.1-mini.csv\")\n",
    "react_df = pd.read_csv(\"data/trustworthy_react_gpt-4.1-mini.csv\")\n",
    "planact_df = pd.read_csv(\"data/trustworthy_planact_gpt-4.1-mini.csv\")\n",
    "planreact_df = pd.read_csv(\"data/trustworthy_planreact_gpt-4.1-mini.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We patched parts of HotPotQA, such as questions with multiple valid answers after our manual review of trust scores."
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_df(df: pd.DataFrame, fixes: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a copy of *df* where the `answer` column has been overwritten\n",
    "    for every row whose `question` matches one of the keys in *fixes*.\n",
    "    \"\"\"\n",
    "    df = df.copy()                     # don’t touch the original\n",
    "\n",
    "    for q, new_ans in fixes.items():\n",
    "        mask = df[\"question\"] == q     # exact match\n",
    "        df.loc[mask, \"answer\"] = new_ans\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = {\n",
    "    \"what is the connection between Peter O'Meara and Norman Dike?\": \"Band of Brothers (Peter O'Meara played the role of Lieutenant Norman Dike in the HBO series Band of Brothers)\", # factually correct addition\n",
    "    \"What profession do Kōbō Abe and Agatha Christie share?\": \"playwright/writer\", # all correct\n",
    "    \"Ian Hunter and Stuart Murdoch, have which musical occupation in common?\": \"lead singer/singer/songwriter\", # all correct\n",
    "    \"Padgate is a suburb of an english town on the banks of the River Mersey whose population was estimated to be 208800 in 2016 but in which unitary authority area is it located?\": \"Warrington\", # Cheshire is incorrect\n",
    "    \"Before finishing her feature film, Something's Got to Give, when did American actress, model and one of the most popular sex symbols of the 1950s, Marilyn Monroe die?\": \"August 4, 1962\", # August 5 is incorrect\n",
    "    \"Which other film did one of the supporting cast in \\\"Sleepless in Seattle\\\" appear?\": \"Now and Then (1995), Independence Day (1996)\", # several supporting members\n",
    "    \"How many different schools does the university, in which Andrew J. Elliot is a professor of psychology, have?\": \"seven\", # University of Rochester has seven schools\n",
    "    \"What was a series of battles during the Revolutionary War, for control of New York City and the state of New Jersey, fought on October 28, 1776 near White Plains, New York?\": \"New York and New Jersey campaign, Battle of White Plains\", # because specific date is provided, plausibly refers to single battle\n",
    "    \"Which contest in California pays homage to an American novelist that won the Novel Prize in Literature in 1954?\": \"The Bad Hemingway Contest, International Imitation Hemingway Competition\", # same entity\n",
    "    \"How old is the female main protagonist of Catching Fire?\": \"17-year-old\", # 16-year-old is incorrect\n",
    "    \"What event at the Asian Junior Athletics Championships has men and women competing at the same time?\": \"4 × 400 m mixed relay\", # 3000 metres steeplechase is incorrect\n",
    "    \"Were Pavel Urysohn and Leonid Levin known for the same type of work?\": \"yes\", # they are mathematicians\n",
    "    \"What city does Paul Clyne and David Soares have in common?\": \"New York, Albany\", # all correct\n",
    "    \"What is the given name of the character depicted as Juliet Hulme in Heavenly Creatures?\": \"Juliet\", # Anne Perry is after the change\n",
    "}\n",
    "\n",
    "zs_df = patch_df(zs_df, patches)\n",
    "zst_df = patch_df(zst_df, patches)\n",
    "react_df = patch_df(react_df, patches)\n",
    "planact_df = patch_df(planact_df, patches)\n",
    "planreact_df = patch_df(planreact_df, patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"zs_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"task_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"What giant silverware company was started as a religious Utopian group and was for many years run by Pierrepont Noyes?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Oneida Limited\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"You are an intelligent Wikipedia agent. You should follow your [Role], [Action_Doc] to take actions. You should decompose your task into executable actions. Your generation should follow the example format. Finish the task if you find the answer. And your answer should be simple and straighforward. You can only take one action per generation. DO NOT repeat your actions.\\n[Role]\\nAnswer questions by searching Wikipedia content.\\n[End of Role]\\n[Constraint]\\nGeneration should be simple and clear.\\n[End of Constraint]\\n[Action_Doc]\\n[{'name': 'Finish', 'description': 'Complete the task with a response.', 'parameters': {'response': 'this is the finish action response. Respond towards the task instruction.'}}, {'name': 'Wikipedia_Search', 'description': 'Using this API to search Wiki content.', 'parameters': {'query': 'the search string. be simple.'}}]\\n[End of Action_Doc]\\nUsing the following action format example to generate well formatted actions.\\n[ActionFormatExample]\\nAction: Finish[{\\\"response\\\": \\\"this is the finish action response. Respond towards the task instruction.\\\"}]\\nAction: Wikipedia_Search[{\\\"query\\\": \\\"the search string. be simple.\\\"}]\\n[End of ActionFormatExample]\\n[Execution]\\nTask: What giant silverware company was started as a religious Utopian group and was for many years run by Pierrepont Noyes?\\n\\nAction: \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_action\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Wikipedia_Search[{\\\"query\\\": \\\"giant silverware company started as religious Utopian group Pierrepont Noyes\\\"}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finish_response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The giant silverware company started as a religious Utopian group and run for many years by Pierrepont Noyes is Oneida Limited.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trust_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041186504134640874,\n        \"min\": 0.9030624904017894,\n        \"max\": 0.9843835874242358,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9323588956193998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1904761904761905,\n        \"max\": 0.1904761904761905,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1904761904761905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Finish\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_params\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"{'query': 'giant silverware company started as religious Utopian group Pierrepont Noyes'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-210ee26c-fe6a-4de3-94c0-e630ebd3e03c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>step</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "      <th>raw_action</th>\n",
       "      <th>finish_response</th>\n",
       "      <th>trust_score</th>\n",
       "      <th>f1</th>\n",
       "      <th>action_name</th>\n",
       "      <th>action_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df</td>\n",
       "      <td>0</td>\n",
       "      <td>What giant silverware company was started as a...</td>\n",
       "      <td>Oneida Limited</td>\n",
       "      <td>You are an intelligent Wikipedia agent. You sh...</td>\n",
       "      <td>Wikipedia_Search[{\"query\": \"giant silverware c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wikipedia_Search</td>\n",
       "      <td>{'query': 'giant silverware company started as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df</td>\n",
       "      <td>1</td>\n",
       "      <td>What giant silverware company was started as a...</td>\n",
       "      <td>Oneida Limited</td>\n",
       "      <td>You are an intelligent Wikipedia agent. You sh...</td>\n",
       "      <td>Wikipedia_Search[{\"query\": \"Pierrepont Noyes s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wikipedia_Search</td>\n",
       "      <td>{'query': 'Pierrepont Noyes silverware company'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df</td>\n",
       "      <td>2</td>\n",
       "      <td>What giant silverware company was started as a...</td>\n",
       "      <td>Oneida Limited</td>\n",
       "      <td>You are an intelligent Wikipedia agent. You sh...</td>\n",
       "      <td>Finish[{\"response\": \"The giant silverware comp...</td>\n",
       "      <td>The giant silverware company started as a reli...</td>\n",
       "      <td>0.984384</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>Finish</td>\n",
       "      <td>{'response': 'The giant silverware company sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-210ee26c-fe6a-4de3-94c0-e630ebd3e03c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-210ee26c-fe6a-4de3-94c0-e630ebd3e03c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-210ee26c-fe6a-4de3-94c0-e630ebd3e03c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-083e1c4e-d989-436c-a7ed-e3de12ee5e00\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-083e1c4e-d989-436c-a7ed-e3de12ee5e00')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-083e1c4e-d989-436c-a7ed-e3de12ee5e00 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                   task_id  step  \\\n",
       "1623  8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df     0   \n",
       "1624  8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df     1   \n",
       "1625  8c8c4afa-9d94-4fc4-a655-6d60a6a5e7df     2   \n",
       "\n",
       "                                               question          answer  \\\n",
       "1623  What giant silverware company was started as a...  Oneida Limited   \n",
       "1624  What giant silverware company was started as a...  Oneida Limited   \n",
       "1625  What giant silverware company was started as a...  Oneida Limited   \n",
       "\n",
       "                                                 prompt  \\\n",
       "1623  You are an intelligent Wikipedia agent. You sh...   \n",
       "1624  You are an intelligent Wikipedia agent. You sh...   \n",
       "1625  You are an intelligent Wikipedia agent. You sh...   \n",
       "\n",
       "                                             raw_action  \\\n",
       "1623  Wikipedia_Search[{\"query\": \"giant silverware c...   \n",
       "1624  Wikipedia_Search[{\"query\": \"Pierrepont Noyes s...   \n",
       "1625  Finish[{\"response\": \"The giant silverware comp...   \n",
       "\n",
       "                                        finish_response  trust_score  \\\n",
       "1623                                                NaN     0.932359   \n",
       "1624                                                NaN     0.903062   \n",
       "1625  The giant silverware company started as a reli...     0.984384   \n",
       "\n",
       "            f1       action_name  \\\n",
       "1623       NaN  Wikipedia_Search   \n",
       "1624       NaN  Wikipedia_Search   \n",
       "1625  0.190476            Finish   \n",
       "\n",
       "                                          action_params  \n",
       "1623  {'query': 'giant silverware company started as...  \n",
       "1624   {'query': 'Pierrepont Noyes silverware company'}  \n",
       "1625  {'response': 'The giant silverware company sta...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Grading"
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adapt the `GRADER_TEMPLATE` from [OpenAI's SimpleQA evaluation](https://github.com/openai/simple-evals/blob/main/simpleqa_eval.py), making only a minor modification to the **NOT\\_ATTEMPTED** classification criteria to better account for cases where agents fail to retrieve relevant information from Wikipedia.\n",
    "\n",
    "> The following are examples of answers classified as **NOT\\_ATTEMPTED**:\n",
    "```\n",
    "Question: What are the names of Barack Obama's children?  \n",
    "Gold target: Malia and Sasha  \n",
    "Predicted answer 1: I don't know.  \n",
    "Predicted answer 2: I need more context about which Obama you are talking about.  \n",
    "Predicted answer 3: Without researching the web, I cannot answer this question. However, I can tell you that Barack Obama has two children.  \n",
    "Predicted answer 4: Barack Obama has two children. I know that one of them is Malia, but I'm not sure about the other one.  \n",
    "Predicted answer 5: I do not have any available information on the names of Barack Obama's children.\n",
    "```\n",
    "These responses are labeled **NOT\\_ATTEMPTED** because:\n",
    "* They do not include the key information from the gold target.\n",
    "* They do not contradict the gold target.\n",
    "* They explicitly express uncertainty or a lack of available information.\n"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_TEMPLATE = \"\"\"\n",
    "Your job is to look at a question, a gold target, and a predicted answer, and then assign a grade of either [\"CORRECT\", \"INCORRECT\", \"NOT_ATTEMPTED\"].\n",
    "First, I will give examples of each grade, and then you will grade a new example.\n",
    "\n",
    "\n",
    "The following are examples of CORRECT predicted answers.\n",
    "```\n",
    "Question: What are the names of Barack Obama's children?\n",
    "Gold target: Malia Obama and Sasha Obama\n",
    "Predicted answer 1: sasha and malia obama\n",
    "Predicted answer 2: most people would say Malia and Sasha, but I'm not sure and would have to double check\n",
    "Predicted answer 3: Barack Obama has two daughters. Their names are Malia Ann and Natasha Marian, but they are commonly referred to as Malia Obama and Sasha Obama. Malia was born on July 4, 1998, and Sasha was born on June 10, 2001.\n",
    "```\n",
    "These predicted answers are all CORRECT because:\n",
    "    - They fully contain the important information in the gold target.\n",
    "    - They do not contain any information that contradicts the gold target.\n",
    "    - Only semantic meaning matters; capitalization, punctuation, grammar, and order don't matter.\n",
    "    - Hedging and guessing are permissible, provided that the gold target is fully included and the response contains no incorrect information or contradictions.\n",
    "\n",
    "\n",
    "The following are examples of INCORRECT predicted answers.\n",
    "```\n",
    "Question: What are the names of Barack Obama's children?\n",
    "Gold target: Malia and Sasha\n",
    "Predicted answer 1: Malia.\n",
    "Predicted answer 2: Malia, Sasha, and Susan.\n",
    "Predicted answer 3: Barack Obama does not have any children.\n",
    "Predicted answer 4: I think it's either Malia and Sasha. Or it could be Malia and Jackie. Or it could be Joey and Malia.\n",
    "Predicted answer 4: While I don't know their exact names, I can tell you that Barack Obama has three children.\n",
    "Predicted answer 5: It's possible you may mean Betsy and Olivia. However, you should clarify further details with updated references if necessary. Is that the correct answer?\n",
    "Predicted answer 6: It may be the case that Obama's child is named James. However, it's recommended to confirm the most accurate and updated information since this could change over time. This model may not always reflect the most current information.\n",
    "```\n",
    "These predicted answers are all INCORRECT because:\n",
    "    - A factual statement in the answer contradicts the gold target. Incorrect statements that have some hedging (e.g., \"it is possible that\", \"although i'm not sure, i think\") are also considered incorrect.\n",
    "\n",
    "\n",
    "The following are examples of NOT_ATTEMPTED predicted answers.\n",
    "```\n",
    "Question: What are the names of Barack Obama's children?\n",
    "Gold target: Malia and Sasha\n",
    "Predicted answer 1: I don't know.\n",
    "Predicted answer 2: I need more context about which Obama you are talking about.\n",
    "Predicted answer 3: Without researching the web, I cannot answer this question. However, I can tell you that Barack Obama has two children.\n",
    "Predicted answer 4: Barack Obama has two children. I know that one of them is Malia, but I'm not sure about the other one.\n",
    "Predicted answer 5: I do not have any available information on the names of Barack Obama's children.\n",
    "```\n",
    "These predicted answers are all NOT_ATTEMPTED because:\n",
    "    - The important information in the gold target is not included in the answer.\n",
    "    - No statements in the answer contradict the gold target.\n",
    "    - They express a lack of knowledge about the question or claim that no information is available.\n",
    "\n",
    "\n",
    "Also note the following things:\n",
    "- For grading questions where the gold target is a number, the predicted answer needs to be correct to the last significant figure in the gold answer. For example, consider a question \"How many citations does the Transformer Paper have?\" with gold target \"120k\".\n",
    "    - Predicted answers \"120k\", \"124k\", and 115k\" are all CORRECT.\n",
    "    - Predicted answers \"100k\" and \"113k\" are INCORRECT.\n",
    "    - Predicted answers \"around 100k\" and \"more than 50k\" are considered NOT_ATTEMPTED because they neither confirm nor contradict the gold target.\n",
    "- The gold target may contain more information than the question. In such cases, the predicted answer only needs to contain the information that is in the question.\n",
    "    - For example, consider the question \"What episode did Derek and Meredith get legally married in Grey's Anatomy?\" with gold target \"Season 7, Episode 20: White Wedding\". Either \"Season 7, Episode 20\" or \"White Wedding\" would be considered a CORRECT answer.\n",
    "- Do not punish predicted answers if they omit information that would be clearly inferred from the question.\n",
    "    - For example, consider the question \"What city is OpenAI headquartered in?\" and the gold target \"San Francisco, California\". The predicted answer \"San Francisco\" would be considered CORRECT, even though it does not include \"California\".\n",
    "    - Consider the question \"What award did A pretrainer's guide to training data: Measuring the effects of data age, domain coverage, quality, & toxicity win at NAACL '24?\", the gold target is \"Outstanding Paper Award\". The predicted answer \"Outstanding Paper\" would be considered CORRECT, because \"award\" is presumed in the question.\n",
    "    - For the question \"What is the height of Jason Wei in meters?\", the gold target is \"1.73 m\". The predicted answer \"1.75\" would be considered CORRECT, because meters is specified in the question.\n",
    "    - For the question \"What is the name of Barack Obama's wife?\", the gold target is \"Michelle Obama\". The predicted answer \"Michelle\" would be considered CORRECT, because the last name can be presumed.\n",
    "- Do not punish for typos in people's name if it's clearly the same name.\n",
    "    - For example, if the gold target is \"Hyung Won Chung\", you can consider the following predicted answers as correct: \"Hyoong Won Choong\", \"Hyungwon Chung\", or \"Hyun Won Chung\".\n",
    "\n",
    "\n",
    "Here is a new example. Simply reply with either CORRECT, INCORRECT, NOT ATTEMPTED. Don't apologize or correct yourself if there was a mistake; we are just trying to grade the answer.\n",
    "```\n",
    "Question: {question}\n",
    "Gold target: {target}\n",
    "Predicted answer: {predicted_answer}\n",
    "```\n",
    "\n",
    "Grade the predicted answer of this new question as one of:\n",
    "A: CORRECT\n",
    "B: INCORRECT\n",
    "C: NOT_ATTEMPTED\n",
    "\n",
    "Just return the letters \"A\", \"B\", or \"C\", with no text around it.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_answer(\n",
    "    question: str,\n",
    "    target: str,\n",
    "    predicted_answer: str,\n",
    "    *,\n",
    "    model: str = \"gpt-4.1\",\n",
    "    temperature: float = 0.0,\n",
    "    max_tokens: int = 1,\n",
    "    retries: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Return \"A\" (correct), \"B\" (incorrect), or \"C\" (not attempted).\n",
    "\n",
    "    Requires `OPENAI_API_KEY` in your environment or you can instantiate\n",
    "    `OpenAI(api_key=\"...\")` and pass it via the `client` kwarg.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    prompt = GRADER_TEMPLATE.format(\n",
    "        question=question,\n",
    "        target=target,\n",
    "        predicted_answer=predicted_answer,\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            text = resp.choices[0].message.content or \"\"\n",
    "            match = re.search(r\"(A|B|C)\", text)\n",
    "            return match.group(0) if match else \"C\"\n",
    "        except Exception as e:\n",
    "            if attempt == retries:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_df_and_save(df: pd.DataFrame, save_file: str) -> pd.DataFrame:\n",
    "\n",
    "    graded_df = df.copy()\n",
    "\n",
    "    mask = graded_df[\"finish_response\"].notna()\n",
    "    rows = graded_df.loc[mask, [\"question\", \"answer\", \"finish_response\"]].itertuples(\n",
    "        index=False, name=None\n",
    "    )\n",
    "\n",
    "    grades = [grade_answer(q, a, r) for q, a, r in tqdm(rows, total=mask.sum(), desc=\"Grading\")]\n",
    "\n",
    "    graded_df[\"llm_grade\"] = pd.Series([pd.NA] * len(df), dtype=\"object\")\n",
    "    graded_df.loc[mask, \"llm_grade\"] = grades\n",
    "\n",
    "    graded_df.to_csv(f\"trustworthy_{name}_gpt-4.1-mini_graded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_data = [\n",
    "    (\"zs\", zs_df),\n",
    "    (\"zst\", zst_df),\n",
    "    (\"react\", react_df),\n",
    "    (\"planact\", planact_df),\n",
    "    (\"planreact\", planreact_df),\n",
    "]\n",
    "\n",
    "for name, df in agent_data:\n",
    "    grade_df_and_save(df, name)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}