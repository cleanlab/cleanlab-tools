# cleanlab-tools
Miscellaneous cookbooks and code made available for purposes of education, reproducibility, and transparency.


| Example                                                                                | Description                                                                                                                               |
|----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------|
| [TLM-Demo-Notebook](TLM-Demo-Notebook/TLM-Demo.ipynb) | A demo notebook showcasing various TLM applications
| [TLM-Record-Matching](TLM-Record-Matching/data_enrichment_record_matching_tutorial.ipynb) | A tutorial showcasing how Cleanlab's Trustworthy Language Model (TLM) can be used for record matching use cases. In particular, this shows how TLM can reliably match records between two different data tables, achieving higher levels of accuracy than existing methods.
| [benchmarking_hallucination_metrics](benchmarking_hallucination_metrics/benchmark_hallucination_metrics.ipynb) | Notebook that compares the performance of popular hallucination detection metrics on a set of hallucination benchmarks.
| [fine_tuning_data_curation](fine_tuning_data_curation/fine_tuning_data_curation.ipynb) | Notebook showing how to use Cleanlab TLM and Cleanlab Studio to detect bad data in instruction tuning LLM datasets.                       |
| [few_shot_prompt_selection](few_shot_prompt_selection/few_shot_prompt_selection.ipynb) | Notebook showing how to clean few-shot examples pool to improve prompt template for OpenAI LLM.                                           |
| [fine_tuning_classification](fine_tuning_classification/fine_tuning_LLM_with_noisy_labels.ipynb) | Notebook showing how to use Cleanlab Studio to improve the accuracy of fine-tuned LLMs for classification tasks.
| [generate_llm_response](generate_llm_response/generate_llm_response.ipynb)             | Notebook showing how to generate LLM responses for customer service requests using Llama 2 and OpenAI's API.                              |
| [gpt4-rag-logprobs](gpt4-rag-logprobs/gpt4-rag-logprobs.ipynb) | Notebook showing how to obtain logprobs from a GPT-4 based RAG system.|
| [fine_tuning_mistral_beavertails](fine_tuning_mistral_beavertails/beavertails.ipynb) | Analyze human annotated AI-safety-related labels (like toxicity) using Cleanlab Studio, and thus generate safer responses from LLMs.|
| [Evaluating_Toxicity_Datasets_Large_Language_Models](jigsaw_ai_safety_keras/Evaluating_Toxicity_Datasets_Large_Language_Models.ipynb) | Notebook on analyzing toxicity annotations in the Jigsaw dataset using Cleanlab Studio.|
| [time_series_automl](time_series_automl/cleanlab_time_series_automl.ipynb) | Notebook showing how to model time series data in a tabular format and use AutoML with Cleanlab Studio to improve out-of-sample accuracy. |
|
