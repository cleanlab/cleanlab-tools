{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0588ac-64ad-4958-9ddc-3d2c4dfdba41",
   "metadata": {},
   "source": [
    "## How to Model Time Series Data in a More General Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf99064-bf5b-4e50-8e10-10626509cc46",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/cleanlab-tools/blob/time-series-automl-notebook/time_series_automl/time_series_automl.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84186538-9eb7-449e-8c5d-25694eee9b38",
   "metadata": {},
   "source": [
    "This notebook delves into enhancing the process of forecasting daily energy consumption levels by transforming a time series dataset into a tabular format using open-source libraries. We explore the application of a popular multiclass classification model and leverage AutoML with cleanlab to significantly boost our out-of-sample accuracy.\n",
    "\n",
    "At a high level we will:\n",
    "\n",
    "- Establish a baseline accuracy by fitting a Prophet forecasting model on our time series data\n",
    "- Convert our time series data into a tabular format by using open-source featurization libraries and then will show that can outperform prophet with a multiclass classification approach.\n",
    "- Use cleanlab’s AutoML platform for multiclass classification to **improve our out-of-sample accuracy for our predictions by 8%** compared to our classification model and by **46%** compared to our forecasting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ced8a9-59b9-405a-a578-d533cc89f5f6",
   "metadata": {},
   "source": [
    "## Initialize time series data for Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c561683-199a-48ee-97ec-95415fcd7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "data = pd.read_csv('PJME_hourly.csv', parse_dates=['Datetime'], index_col='Datetime')\n",
    "\n",
    "# Assuming pjme_data is loaded as before\n",
    "daily_data = data.resample('D').mean() \n",
    "\n",
    "# Prepare data for Prophet\n",
    "daily_data.reset_index(inplace=True)\n",
    "daily_data.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85f6a2-fb50-4234-bca8-af54491acfa5",
   "metadata": {},
   "source": [
    "## Initialize time series data for featurization into a tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd719a8-62a2-45ed-93ba-a9b7288459bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reset the datetime\n",
    "data[\"Datetime\"] = data.index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Create copy for multiclass data \n",
    "df = data.copy()\n",
    "\n",
    "# Convert the datetime column\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])  # Adjust the 'datetime' column name as necessary\n",
    "df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Obtain day and hour\n",
    "df['Date'] = pd.to_datetime(df['Datetime']).dt.floor('D')  \n",
    "df['Hour'] = pd.to_datetime(df['Datetime']).dt.hour\n",
    "\n",
    "# Create multi-index feature df to compute time series features on\n",
    "features = df.set_index(['Date', 'Hour'])  \n",
    "features.drop(\"Datetime\", inplace=True, axis=1)\n",
    "\n",
    "# Split the data into training and testing sets, respecting the temporal order\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, features[\"PJME_MW\"], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Get group lengths\n",
    "train_lengths = X_train.groupby(level=0).size()\n",
    "test_lengths = X_test.groupby(level=0).size()\n",
    "\n",
    "# Obtain common length value for train/test data\n",
    "train_common_length = train_lengths.mode().iloc[0]\n",
    "test_common_length = test_lengths.mode().iloc[0]\n",
    "\n",
    "# Filter train/test data to groups with same common length for featurizer\n",
    "X_train = X_train.groupby(level=0).filter(lambda x: len(x) == train_common_length)\n",
    "X_test = X_test.groupby(level=0).filter(lambda x: len(x) == test_common_length)\n",
    "\n",
    "# Create quartiles based on training data to avoid leakage\n",
    "quartiles = [X_train['PJME_MW'].quantile(q) for q in [0.25, 0.50, 0.75]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068710b-9f76-4988-a43f-bb8a550c1d6d",
   "metadata": {},
   "source": [
    "## Train and Evaluate Prophet Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb619ec-f09d-4030-9f28-7a128e434f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (4847, 2)\n",
      "Testing Set Shape: (1212, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cutoff date at 2015-04-09\n",
    "cutoff_index = int(len(daily_data) * 0.8)\n",
    "\n",
    "# Use 80% of data for training set and 20% for test set\n",
    "train_df = daily_data.iloc[:cutoff_index]\n",
    "test_df = daily_data.iloc[cutoff_index:]\n",
    "\n",
    "print(\"Training Set Shape:\", train_df.shape)\n",
    "print(\"Testing Set Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3fd144e-9e93-4b7b-8808-991e52ea40b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>2015-04-05</td>\n",
       "      <td>24577.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>26996.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>27177.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>29136.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>30535.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds             y\n",
       "4842 2015-04-05  24577.500000\n",
       "4843 2015-04-06  26996.666667\n",
       "4844 2015-04-07  27177.833333\n",
       "4845 2015-04-08  29136.041667\n",
       "4846 2015-04-09  30535.291667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa64b01-ca61-4b8d-ab51-58cb8eb6e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2015-04-10</td>\n",
       "      <td>29190.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>24774.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>2015-04-12</td>\n",
       "      <td>24407.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>26825.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>26952.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds             y\n",
       "4847 2015-04-10  29190.166667\n",
       "4848 2015-04-11  24774.291667\n",
       "4849 2015-04-12  24407.625000\n",
       "4850 2015-04-13  26825.333333\n",
       "4851 2015-04-14  26952.125000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c71781e-7e82-407b-8200-a2ce3333ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mturk/mturk-work/cleanlab-tools/time-series-automl-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "22:59:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:59:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize model and train it on training data\n",
    "model = Prophet()\n",
    "model.fit(train_df)\n",
    "\n",
    "# Create a dataframe for future predictions covering the test period\n",
    "future = model.make_future_dataframe(periods=len(test_df), freq='D')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Categorize forecasted daily values into quartiles based on the thresholds\n",
    "forecast['quartile'] = pd.cut(forecast['yhat'], bins = [-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])\n",
    "\n",
    "# Extract the forecasted quartiles for the test period\n",
    "forecasted_quartiles = forecast.iloc[-len(test_df):]['quartile'].astype(int)\n",
    "\n",
    "\n",
    "# Categorize actual daily values in the test set into quartiles\n",
    "test_df['quartile'] = pd.cut(test_df['y'], bins=[-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])\n",
    "actual_test_quartiles = test_df['quartile'].astype(int)\n",
    "\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(actual_test_quartiles, forecasted_quartiles)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b039e99-2ac9-4a36-85b9-f874a5947144",
   "metadata": {},
   "source": [
    "## Convert time series data to tabular format through featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4755933-2bc5-4f18-bb9f-d07769075603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|███████████████████| 4817/4817 [00:00<00:00, 8337.50it/s]\n",
      "Feature Extraction: 100%|███████████████████| 1205/1205 [00:00<00:00, 9386.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import tsfel\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n",
    "\n",
    "# Define tsfresh feature extractor\n",
    "tsfresh_trafo = TSFreshFeatureExtractor(default_fc_parameters=\"minimal\")\n",
    "\n",
    "# Transform the training data using the feature extractor\n",
    "X_train_transformed = tsfresh_trafo.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same feature extractor\n",
    "X_test_transformed = tsfresh_trafo.transform(X_test)\n",
    "\n",
    "# Retrieves a pre-defined feature configuration file to extract all available features\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "# Function to compute tsfel features per day\n",
    "def compute_features(group):\n",
    "    # TSFEL expects a DataFrame with the data in columns, so we transpose the input group\n",
    "    features = tsfel.time_series_features_extractor(cfg, group, fs=1, verbose=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "# Group by the 'day' level of the index and apply the feature computation\n",
    "train_features_per_day = X_train.groupby(level='Date').apply(compute_features).reset_index(drop=True)\n",
    "test_features_per_day = X_test.groupby(level='Date').apply(compute_features).reset_index(drop=True)\n",
    "\n",
    "# Combine each featurization into a set of combined features for our train/test data\n",
    "train_combined_df = pd.concat([X_train_transformed, train_features_per_day], axis=1)\n",
    "test_combined_df = pd.concat([X_test_transformed, test_features_per_day], axis=1)\n",
    "\n",
    "# Filter out features that are highly correlated with our target variable\n",
    "column_of_interest = \"PJME_MW__mean\"\n",
    "train_corr_matrix = train_combined_df.corr()\n",
    "train_corr_with_interest = train_corr_matrix[column_of_interest]\n",
    "null_corrs = pd.Series(train_corr_with_interest.isnull())\n",
    "false_features = null_corrs[null_corrs].index.tolist()\n",
    "\n",
    "columns_to_exclude = list(set(train_corr_with_interest[abs(train_corr_with_interest) > 0.8].index.tolist() + false_features))\n",
    "columns_to_exclude.remove(column_of_interest)\n",
    "\n",
    "# Filtered DataFrame excluding columns with high correlation to the column of interest\n",
    "train_combined_df = train_combined_df.drop(columns=columns_to_exclude)\n",
    "test_combined_df = test_combined_df.drop(columns=columns_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d50faef-1dcd-4900-8fe2-15001ccd4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW__standard_deviation</th>\n",
       "      <th>PJME_MW__variance</th>\n",
       "      <th>PJME_MW_Centroid</th>\n",
       "      <th>PJME_MW_Entropy</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_0</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_1</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_10</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_11</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_12</th>\n",
       "      <th>PJME_MW_FFT mean coefficient_2</th>\n",
       "      <th>...</th>\n",
       "      <th>PJME_MW_Spectral roll-off</th>\n",
       "      <th>PJME_MW_Spectral skewness</th>\n",
       "      <th>PJME_MW_Spectral slope</th>\n",
       "      <th>PJME_MW_Spectral spread</th>\n",
       "      <th>PJME_MW_Spectral variation</th>\n",
       "      <th>PJME_MW_Standard deviation</th>\n",
       "      <th>PJME_MW_Variance</th>\n",
       "      <th>PJME_MW_Wavelet entropy</th>\n",
       "      <th>PJME_MW_Wavelet variance_4</th>\n",
       "      <th>PJME_MW_Wavelet variance_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4097.961271</td>\n",
       "      <td>1.679329e+07</td>\n",
       "      <td>12.727435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.207144e+06</td>\n",
       "      <td>1.736704e+08</td>\n",
       "      <td>45827.482018</td>\n",
       "      <td>79791.456899</td>\n",
       "      <td>56591.123457</td>\n",
       "      <td>1.758157e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.166394</td>\n",
       "      <td>-0.745390</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>0.247164</td>\n",
       "      <td>4097.961271</td>\n",
       "      <td>1.679329e+07</td>\n",
       "      <td>1.896687</td>\n",
       "      <td>1.664806e+08</td>\n",
       "      <td>2.229225e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3718.008117</td>\n",
       "      <td>1.382358e+07</td>\n",
       "      <td>12.554067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.425893e+06</td>\n",
       "      <td>1.564219e+08</td>\n",
       "      <td>65442.702058</td>\n",
       "      <td>94361.095951</td>\n",
       "      <td>20417.234568</td>\n",
       "      <td>1.455746e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.700734</td>\n",
       "      <td>-0.751053</td>\n",
       "      <td>0.046701</td>\n",
       "      <td>0.234079</td>\n",
       "      <td>3718.008117</td>\n",
       "      <td>1.382358e+07</td>\n",
       "      <td>1.895960</td>\n",
       "      <td>1.534287e+08</td>\n",
       "      <td>2.099539e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3241.304817</td>\n",
       "      <td>1.050606e+07</td>\n",
       "      <td>12.395692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.600067e+06</td>\n",
       "      <td>1.015409e+08</td>\n",
       "      <td>1155.348647</td>\n",
       "      <td>71254.542792</td>\n",
       "      <td>19028.669753</td>\n",
       "      <td>1.227644e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.583426</td>\n",
       "      <td>-0.753413</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0.280831</td>\n",
       "      <td>3241.304817</td>\n",
       "      <td>1.050606e+07</td>\n",
       "      <td>1.895280</td>\n",
       "      <td>1.377279e+08</td>\n",
       "      <td>1.852873e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2259.371710</td>\n",
       "      <td>5.104761e+06</td>\n",
       "      <td>12.204000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.219601e+04</td>\n",
       "      <td>6.502275e+07</td>\n",
       "      <td>35704.669659</td>\n",
       "      <td>92795.408167</td>\n",
       "      <td>11306.777778</td>\n",
       "      <td>5.256738e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.868139</td>\n",
       "      <td>-0.750643</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.267369</td>\n",
       "      <td>2259.371710</td>\n",
       "      <td>5.104761e+06</td>\n",
       "      <td>1.898934</td>\n",
       "      <td>1.031623e+08</td>\n",
       "      <td>1.269314e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3250.463504</td>\n",
       "      <td>1.056551e+07</td>\n",
       "      <td>12.751234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.678627e+05</td>\n",
       "      <td>2.307445e+08</td>\n",
       "      <td>8367.989724</td>\n",
       "      <td>2063.814511</td>\n",
       "      <td>1591.123457</td>\n",
       "      <td>3.033723e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>6.800978</td>\n",
       "      <td>-0.762032</td>\n",
       "      <td>0.036911</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>3250.463504</td>\n",
       "      <td>1.056551e+07</td>\n",
       "      <td>1.893653</td>\n",
       "      <td>1.547531e+08</td>\n",
       "      <td>1.735752e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PJME_MW__standard_deviation  PJME_MW__variance  PJME_MW_Centroid  \\\n",
       "0                  4097.961271       1.679329e+07         12.727435   \n",
       "1                  3718.008117       1.382358e+07         12.554067   \n",
       "2                  3241.304817       1.050606e+07         12.395692   \n",
       "3                  2259.371710       5.104761e+06         12.204000   \n",
       "4                  3250.463504       1.056551e+07         12.751234   \n",
       "\n",
       "   PJME_MW_Entropy  PJME_MW_FFT mean coefficient_0  \\\n",
       "0              1.0                    5.207144e+06   \n",
       "1              1.0                    3.425893e+06   \n",
       "2              1.0                    2.600067e+06   \n",
       "3              1.0                    4.219601e+04   \n",
       "4              1.0                    7.678627e+05   \n",
       "\n",
       "   PJME_MW_FFT mean coefficient_1  PJME_MW_FFT mean coefficient_10  \\\n",
       "0                    1.736704e+08                     45827.482018   \n",
       "1                    1.564219e+08                     65442.702058   \n",
       "2                    1.015409e+08                      1155.348647   \n",
       "3                    6.502275e+07                     35704.669659   \n",
       "4                    2.307445e+08                      8367.989724   \n",
       "\n",
       "   PJME_MW_FFT mean coefficient_11  PJME_MW_FFT mean coefficient_12  \\\n",
       "0                     79791.456899                     56591.123457   \n",
       "1                     94361.095951                     20417.234568   \n",
       "2                     71254.542792                     19028.669753   \n",
       "3                     92795.408167                     11306.777778   \n",
       "4                      2063.814511                      1591.123457   \n",
       "\n",
       "   PJME_MW_FFT mean coefficient_2  ...  PJME_MW_Spectral roll-off  \\\n",
       "0                    1.758157e+08  ...                   0.083333   \n",
       "1                    1.455746e+08  ...                   0.083333   \n",
       "2                    1.227644e+08  ...                   0.083333   \n",
       "3                    5.256738e+07  ...                   0.083333   \n",
       "4                    3.033723e+07  ...                   0.041667   \n",
       "\n",
       "   PJME_MW_Spectral skewness  PJME_MW_Spectral slope  PJME_MW_Spectral spread  \\\n",
       "0                   5.166394               -0.745390                 0.050256   \n",
       "1                   5.700734               -0.751053                 0.046701   \n",
       "2                   5.583426               -0.753413                 0.044695   \n",
       "3                   5.868139               -0.750643                 0.052614   \n",
       "4                   6.800978               -0.762032                 0.036911   \n",
       "\n",
       "   PJME_MW_Spectral variation  PJME_MW_Standard deviation  PJME_MW_Variance  \\\n",
       "0                    0.247164                 4097.961271      1.679329e+07   \n",
       "1                    0.234079                 3718.008117      1.382358e+07   \n",
       "2                    0.280831                 3241.304817      1.050606e+07   \n",
       "3                    0.267369                 2259.371710      5.104761e+06   \n",
       "4                    0.058819                 3250.463504      1.056551e+07   \n",
       "\n",
       "   PJME_MW_Wavelet entropy  PJME_MW_Wavelet variance_4  \\\n",
       "0                 1.896687                1.664806e+08   \n",
       "1                 1.895960                1.534287e+08   \n",
       "2                 1.895280                1.377279e+08   \n",
       "3                 1.898934                1.031623e+08   \n",
       "4                 1.893653                1.547531e+08   \n",
       "\n",
       "   PJME_MW_Wavelet variance_5  \n",
       "0                2.229225e+08  \n",
       "1                2.099539e+08  \n",
       "2                1.852873e+08  \n",
       "3                1.269314e+08  \n",
       "4                1.735752e+08  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to classify each value into a quartile\n",
    "def classify_into_quartile(value):\n",
    "    if value < quartiles[0]:\n",
    "        return 1  \n",
    "    elif value < quartiles[1]:\n",
    "        return 2  \n",
    "    elif value < quartiles[2]:\n",
    "        return 3  \n",
    "    else:\n",
    "        return 4  \n",
    "\n",
    "X_train_transformed = train_combined_df.copy()\n",
    "X_test_transformed = test_combined_df.copy()\n",
    "\n",
    "y_train = X_train_transformed[\"PJME_MW__mean\"]\n",
    "X_train_transformed.drop(\"PJME_MW__mean\", inplace=True, axis=1)\n",
    "\n",
    "y_test = X_test_transformed[\"PJME_MW__mean\"]\n",
    "X_test_transformed.drop(\"PJME_MW__mean\", inplace=True, axis=1)\n",
    "\n",
    "y_train_labels = y_train.apply(classify_into_quartile)\n",
    "y_test_labels = y_test.apply(classify_into_quartile)\n",
    "\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54236393-8463-4c83-8cc0-c28b26db2a5a",
   "metadata": {},
   "source": [
    "## Train and Evaluate GradientBoostingClassifier Model on multiclass tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234d7a2c-e35f-41cf-8daa-2776d5a698ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PJME_MW__mean\n",
      "2    1795\n",
      "3    1333\n",
      "4    1023\n",
      "1     666\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34605d9-f596-44e3-a379-2b20febd9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=20,\n",
    "    max_features='sqrt',\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbc.fit(X_train_transformed, y_train_labels)\n",
    "\n",
    "\n",
    "y_pred_gbc = gbc.predict(X_test_transformed)\n",
    "print(f'Accuracy: {accuracy_score(y_test_labels, y_pred_gbc):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210a381-3159-4891-8cd3-de658d77c06f",
   "metadata": {},
   "source": [
    "## Using AutoML with Cleanlab Studio to improve out-of-sample accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b9036-01c7-4b28-89c8-2f8fb4adffd4",
   "metadata": {},
   "source": [
    "Use your API key to instantiate a Studio object, which can be used to analyze your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edae19-73bc-466a-aa49-865f2a9a915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# you can find your Cleanlab Studio API key by going to app.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# initialize studio object\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021f59c-7a49-49da-a69a-36132eb88e0f",
   "metadata": {},
   "source": [
    "Next load the dataset into Cleanlab Studio (more details/options can be found in [this guide](https://help.cleanlab.ai/guide/quickstart/api/#uploading-a-dataset)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d65672-9c3c-4872-b3e0-9fb60ec4d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(dataset_path, dataset_name=\"YOUR DATASET NAME HERE\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dff171-cfe8-4329-9f24-43c9746e2c0c",
   "metadata": {},
   "source": [
    "Now you can create a project using this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4b0c1-48fb-46d5-8a3c-37dbd60b4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"YOUR PROJECT NAME HERE\",\n",
    "    modality=\"tabular\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=\"YOUR LABEL COLUMN HERE\",\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee8172-3e49-4fbd-be67-77044ec215ba",
   "metadata": {},
   "source": [
    "You can then deploy a model using your Cleanlab Studio project to get AutoML results. [This guide](https://help.cleanlab.ai/tutorials/inference_api/) is a useful reference to learn more about model deployment. Below is some example code to run inference on a model once you have deployed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428aab0-b046-40d1-a817-aa00827ab8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from Studio\n",
    "# you can find your model ID in the models table on the dashboard!\n",
    "model_id = \"<YOUR_MODEL_ID>\"\n",
    "model = studio.get_model(model_id)\n",
    "\n",
    "predictions = model.predict(test_data, return_pred_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7d67b0e-6995-4667-accf-c49ab65c7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_automl_cleanlab = pd.read_csv(\"quartile-multiclass-pjme-testing-data_pred_probs.csv\")\n",
    "y_pred_automl_cleanlab = y_pred_automl_cleanlab[\"Suggested Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b0f0b4-6b3d-4c76-8e09-7a285ba312b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8880\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test_labels, y_pred_automl_cleanlab):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-automl-env",
   "language": "python",
   "name": "time-series-automl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
