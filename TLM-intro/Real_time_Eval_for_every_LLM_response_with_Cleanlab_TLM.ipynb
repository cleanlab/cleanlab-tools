{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d28JCTXqODOB"
      },
      "source": [
        "# Real-time Eval for every LLM response with Cleanlab TLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_V8qJHRTJdBW"
      },
      "outputs": [],
      "source": [
        "#@title Install Cleanlab\n",
        "%pip install --upgrade cleanlab-studio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwns730hK4a-",
        "outputId": "467fa637-3a32-4c51-b6db-438fd9703ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TLM model used:  gpt-4o-mini \n",
            "\n",
            "TLM response:  The third month of the year alphabetically is \"March.\" The months in alphabetical order are:\n",
            "\n",
            "1. April\n",
            "2. August\n",
            "3. December\n",
            "4. February\n",
            "5. January\n",
            "6. July\n",
            "7. June\n",
            "8. March\n",
            "9. May\n",
            "10. November\n",
            "11. October\n",
            "12. September \n",
            "\n",
            "TLM trustworthiness score:  0.4979648802626605 \n",
            "\n",
            "TLM Explanation:  The answer provided states that \"March\" is the third month of the year alphabetically. However, when listing the months in alphabetical order, \"March\" is actually the eighth month. Therefore,  incorrect. \n",
            "This response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \n",
            "December. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from cleanlab_studio import Studio\n",
        "\n",
        "studio = Studio(\"<YOUR_API_KEY>\")  # Get your API key from https://tlm.cleanlab.ai\n",
        "\n",
        "tlm = studio.TLM(options={\"log\": [\"explanation\"], \"model\": \"gpt-4o-mini\"}) # supports GPT, Claude, etc\n",
        "\n",
        "# Use TLM like GPT (with more accurate results). Returns response, trustworthiness score, explanation\n",
        "out = tlm.prompt(\"What's the third month of the year alphabetically?\")\n",
        "print(\"TLM model used: \", tlm.get_model_name(), \"\\n\")\n",
        "print(\"TLM response: \", out['response'], \"\\n\")\n",
        "print(\"TLM trustworthiness score: \", out['trustworthiness_score'], \"\\n\")\n",
        "print(\"TLM Explanation: \", out['log']['explanation'], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwCJ4aDNLcr8"
      },
      "source": [
        "## You can also use TLM to score the trustworthiness of any response to a given prompt.\n",
        "Use `tlm.get_trustworthiness_score` which returns a numerical value between 0-1.\n",
        " - Enables you to use TLM with responses from your own custom LLM or LLM in production.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Nx0LxGLbGw",
        "outputId": "733be2a4-4550-4bbd-a9aa-010e8a2e5443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trustworthiness Score:  0.9997738711822411\n",
            "Explanation:  Did not find a reason to doubt trustworthiness.\n"
          ]
        }
      ],
      "source": [
        "# TLM returns a high score when the LLM/RAG/Agent is accurate\n",
        "response = tlm.get_trustworthiness_score(\"What's the first month of the year?\", response=\"January\")\n",
        "print(\"Trustworthiness Score: \", response[\"trustworthiness_score\"])\n",
        "print(\"Explanation: \", response[\"log\"][\"explanation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTgsT_j8LZqk",
        "outputId": "c07401dc-b01d-4d90-ad07-d07e1f3b4084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trustworthiness Score:  0.04739682241488771\n",
            "Explanation:  The first month of the year is January, not February. Therefore,  factually incorrect. \n",
            "This response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \n",
            "January.\n"
          ]
        }
      ],
      "source": [
        "# TLM returns a low score when the LLM/RAG/Agent is untrustworthy\n",
        "response = tlm.get_trustworthiness_score(\"What's the first month of the year?\", response=\"February\")\n",
        "print(\"Trustworthiness Score: \", response[\"trustworthiness_score\"])\n",
        "print(\"Explanation: \", response[\"log\"][\"explanation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xorjnv3kOj8D"
      },
      "source": [
        "\n",
        "\n",
        "# How to interpret the TLM trustworthiness score:\n",
        " - `1.0 >= trustworthiness > 0.9` -- highly reliable reponse you can fully trust\n",
        " - `0.9 >= trustworthiness > 0.7` -- sometimes a bad retrieval (if RAG), hallucination, or wrong reponse\n",
        " - `0.7 >= trustworthiness > 0.3` -- likely a bad retrieval (if RAG), hallucination, or wrong reponse\n",
        " - `0.3 >= trustworthiness >= 0.0` -- near-always a bad retrieval (if RAG), hallucination, or wrong reponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6d_W5g-OnDH"
      },
      "outputs": [],
      "source": [
        "# Run your own real-time evaluation of LLM outputs with TLM here:\n",
        "tlm.prompt(\"ENTER_YOUR_OWN_PROMPT_HERE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
