{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to call the TLM REST API directly\n",
    "\n",
    "Although the Trustworthy Language Model officially offers a Python client library and can be used via OpenAI's Python client library, you can still use TLM with another programming language (eg. Typescript) by directly calling TLM's backend REST API.\n",
    "\n",
    "Here we demonstrate how to call the REST API using Python, just for reference. Our code here is simply making http requests, you can use any other programming language with http lib/tools by providing the necessary payload and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TLM API key, model, and quality preset\n",
    "# More details on models supported and quality presets can be found here: https://help.cleanlab.ai/reference/python/trustworthy_language_model/#class-tlmoptions\n",
    "API_KEY = 'api_key'\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "QUALITY_PRESET = \"medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prompt API request to TLM to get back a response and trustworthiness score\n",
    "\n",
    "Note: The `confidence_score` parameter returned in the REST API response is the same as `trustworthiness_score` returned by the Python client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence_score': 0.9895625234542792,\n",
       " 'log': {'explanation': 'Did not find a reason to doubt trustworthiness.'},\n",
       " 'response': 'The first month of the year is January.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.cleanlab.ai/api/v0/trustworthy_llm/prompt\"\n",
    "\n",
    "\n",
    "def make_prompt_api_request(prompt):\n",
    "    payload = json.dumps({\n",
    "        \"task\": \"default\",\n",
    "        \"quality\": QUALITY_PRESET,\n",
    "        \"prompt\": prompt,\n",
    "        \"options\": {\n",
    "            \"model\": MODEL,\n",
    "            \"log\": [\"explanation\"]\n",
    "        }\n",
    "    })\n",
    "    headers = {\n",
    "        'authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response_json = requests.request(\"POST\", url, headers=headers, data=payload).json() \n",
    "    # This field is not useful\n",
    "    del response_json['deberta_success']\n",
    "    return response_json\n",
    "\n",
    "make_prompt_api_request(\"What's the first month of the year?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Trusworthiness Score API request to TLM to get back a trustworthiness score\n",
    "\n",
    "Note: The `confidence_score` parameter returned in the REST API response is the same as `trustworthiness_score` returned by the Python client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence_score': 0.018654437417664177,\n",
       " 'log': {'explanation': \"The text expresses a strong positive sentiment towards the product, indicating love for it. Therefore, classifying it as negative is incorrect. A better response would be to classify it as positive. \\nThis response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \\nPositive.\"}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.cleanlab.ai/api/v0/trustworthy_llm/get_confidence_score\"\n",
    "\n",
    "def make_score_api_request(prompt, response):\n",
    "    payload = json.dumps({\n",
    "        \"task\": \"classification\",\n",
    "        \"quality\": QUALITY_PRESET,\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"options\": {\n",
    "            \"model\": MODEL,\n",
    "            \"log\": [\"explanation\"]\n",
    "        }\n",
    "    })\n",
    "    headers = {\n",
    "        'authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response_json = requests.request(\"POST\", url, headers=headers, data=payload).json()\n",
    "    # This field is not useful\n",
    "    del response_json['deberta_success']\n",
    "    return response_json\n",
    "\n",
    "make_score_api_request(\"Classify this text as positive or negative: 'I love this product!'\", \"negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
