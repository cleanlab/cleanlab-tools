{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to call the TLM REST API directly\n",
    "\n",
    "Although the Trustworthy Language Model officially offers a Python client library and can be used via OpenAI's Python client library, you can still use TLM with another programming language (eg. Typescript) by directly calling TLM's backend REST API.\n",
    "\n",
    "Here we demonstrate how to call the REST API using Python, just for reference. Our code here is simply making http requests, you can use any other programming language with http lib/tools by providing the necessary payload and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TLM API key, model, and quality preset\n",
    "# More details on models supported and quality presets can be found here: https://help.cleanlab.ai/reference/python/trustworthy_language_model/#class-tlmoptions\n",
    "API_KEY = '<API_KEY>'\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "QUALITY_PRESET = \"medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prompt API request to TLM to get back a response and trustworthiness score\n",
    "\n",
    "Note: The `confidence_score` parameter returned in the REST API response is the same as `trustworthiness_score` returned by the Python client library.\n",
    "\n",
    "You can check out the API documentation for more details on inputs and outputs: https://help.cleanlab.ai/tlm/api/python/tlm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### JSON payload structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'default',\n",
       " 'quality': 'medium',\n",
       " 'prompt': \"What's the first month of the year?\",\n",
       " 'options': {'model': 'gpt-4o-mini', 'log': ['explanation']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"task\": \"default\",\n",
    "  \"quality\": \"medium\",\n",
    "  \"prompt\": \"What's the first month of the year?\",\n",
    "  \"options\": {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"log\": [\"explanation\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs:\n",
    "- `prompt` (required): prompt (or list of prompts) for the TLM to evaluate, inclusive of the user's query and any system instructions.\n",
    "- `task` (optional): determines details of the algorithm used for scoring LLM response trustworthiness, i.e. `default`, `classification`, or `code_generation`.\n",
    "- `quality` (optional): controls the quality of TLM responses and trustworthiness scores vs. latency/costs.\n",
    "- `options` (optional):\n",
    "  - `model` (optional): underlying base LLM to use (better models yield better results, faster models yield faster/cheaper results).\n",
    "  - `log` (optional): optionally specify additional logs or metadata that TLM should return. For instance, include “explanation” here to get explanations of why a response is scored with low trustworthiness.\n",
    "\n",
    "\n",
    "See more [here](https://help.cleanlab.ai/tlm/api/python/tlm/)\n",
    "\n",
    "### Outputs:\n",
    "- `response`: The response from the model.\n",
    "- `confidence_score`: score between 0-1 corresponding to the trustworthiness of the response. A higher score indicates a higher confidence that the response is correct/good.\n",
    "- `explanation`: explanation of why a response is scored with low trustworthiness, if `log` includes `explanation`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence_score': 0.9895625234542792,\n",
       " 'log': {'explanation': 'Did not find a reason to doubt trustworthiness.'},\n",
       " 'response': 'The first month of the year is January.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.cleanlab.ai/api/v0/trustworthy_llm/prompt\"\n",
    "\n",
    "\n",
    "def make_prompt_api_request(prompt):\n",
    "    payload = json.dumps({\n",
    "        \"task\": \"default\",\n",
    "        \"quality\": QUALITY_PRESET,\n",
    "        \"prompt\": prompt,\n",
    "        \"options\": {\n",
    "            \"model\": MODEL,\n",
    "            \"log\": [\"explanation\"]\n",
    "        }\n",
    "    })\n",
    "    headers = {\n",
    "        'authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response_json = requests.request(\"POST\", url, headers=headers, data=payload).json() \n",
    "    # This field is not useful\n",
    "    del response_json['deberta_success']\n",
    "    return response_json\n",
    "\n",
    "make_prompt_api_request(\"What's the first month of the year?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Trusworthiness Score API request to TLM to get back a trustworthiness score\n",
    "\n",
    "Note: The `confidence_score` parameter returned in the REST API response is the same as `trustworthiness_score` returned by the Python client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence_score': 0.018654437417664177,\n",
       " 'log': {'explanation': \"The text expresses a strong positive sentiment towards the product, indicating love for it. Therefore, classifying it as negative is incorrect. A better response would be to classify it as positive. \\nThis response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \\nPositive.\"}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.cleanlab.ai/api/v0/trustworthy_llm/get_confidence_score\"\n",
    "\n",
    "def make_score_api_request(prompt, response):\n",
    "    payload = json.dumps({\n",
    "        \"task\": \"classification\",\n",
    "        \"quality\": QUALITY_PRESET,\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"options\": {\n",
    "            \"model\": MODEL,\n",
    "            \"log\": [\"explanation\"]\n",
    "        }\n",
    "    })\n",
    "    headers = {\n",
    "        'authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response_json = requests.request(\"POST\", url, headers=headers, data=payload).json()\n",
    "    # This field is not useful\n",
    "    del response_json['deberta_success']\n",
    "    return response_json\n",
    "\n",
    "make_score_api_request(\"Classify this text as positive or negative: 'I love this product!'\", \"negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
